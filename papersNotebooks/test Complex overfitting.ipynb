{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import os\n",
    "os.chdir('..')\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa\n",
    "from utils.strechableNumpyArray import StrechableNumpyArray\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import functools\n",
    "from tensorflow.contrib.signal.python.ops import window_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Encoder\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/input_data:0\", shape=(256, 16, 257, 4), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_0/Conv2D:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization/cond/Merge:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_1/Conv2D:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_1:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_2/cond/Merge:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_2/Conv2D:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_2:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_3/cond/Merge:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_3/Conv2D:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_3:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_4/cond/Merge:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_4/Conv2D:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_4:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_5/cond/Merge:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_5/Conv2D:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_5:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_6/cond/Merge:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "---------\n",
      "Fully\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_6/cond/Merge:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Fully/MatMul:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Relu:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/batch_normalization/batchnorm/add_1:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape_1:0\", shape=(256, 8, 8, 32), dtype=float32)\n",
      "---------\n",
      "Decoder\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape_1:0\", shape=(256, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_0/conv2d_transpose:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization/cond/Merge:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_1/conv2d_transpose:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_1:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_2/cond/Merge:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_2/conv2d_transpose:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_2:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_3/cond/Merge:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Reshape:0\", shape=(256, 8, 257, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_3/conv2d_transpose:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_3:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_4/cond/Merge:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Reshape_1:0\", shape=(256, 11, 257, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_4/conv2d_transpose:0\", shape=(256, 11, 257, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "import pickle\n",
    "\n",
    "from architecture.contextEncoderArchitecture import ContextEncoderArchitecture\n",
    "from system.contextEncoderSystem import ContextEncoderSystem\n",
    "from system.preAndPostProcessor import PreAndPostProcessor\n",
    "\n",
    "architecturesParametersFile = \"complex_network_parameters.pkl\"\n",
    "sessionsName = \"Papers_FMA_Context_Encoder\"\n",
    "\n",
    "with open(architecturesParametersFile, 'rb') as savedFile:\n",
    "    Context_Encoder_parameters = pickle.load(savedFile)\n",
    "\n",
    "aContextEncoderArchitecture = ContextEncoderArchitecture(*Context_Encoder_parameters.architectureParameters())\n",
    "aPreProcessor = PreAndPostProcessor(*Context_Encoder_parameters.preProcessorParameters())\n",
    "aContextEncoderSystem = ContextEncoderSystem(aContextEncoderArchitecture, Context_Encoder_parameters.batchSize(),\n",
    "                                             aPreProcessor, sessionsName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000\n",
    "start_in_seconds = 0.1\n",
    "gap_length = 1024\n",
    "side_length = 2048\n",
    "\n",
    "starting_sample_left_side = int(sr*start_in_seconds)\n",
    "ending_sample_left_side = starting_sample_left_side + side_length\n",
    "starting_sample_right_side = ending_sample_left_side + gap_length\n",
    "ending_sample_right_side = starting_sample_right_side + side_length\n",
    "\n",
    "best_step = 2567124 # trained only on FMA\n",
    "\n",
    "\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pavlovs_SNR(y_orig, y_inp, onAxis=(1,)):\n",
    "    norm_y_orig = _squaredEuclideanNorm(y_orig, onAxis)\n",
    "    norm_y_orig_minus_y_inp = _squaredEuclideanNorm(y_orig - y_inp, onAxis)\n",
    "    return 10 * np.log10(norm_y_orig / norm_y_orig_minus_y_inp)\n",
    "\n",
    "def _squaredEuclideanNorm(vector, onAxis=(1,)):\n",
    "    squared = np.square(vector)\n",
    "    summed = np.sum(squared, axis=onAxis)\n",
    "    return summed\n",
    "\n",
    "def computeInpaintingSNRFor(signals_batch):\n",
    "    original_signals = signals_batch[:, 5120:5120*2]\n",
    "    original_gaps = signals_batch[:, 5120+2048:5120+2048+1024]\n",
    "    generatedSpecs = aContextEncoderSystem.reconstructAudio(original_signals, model_num=best_step)\n",
    "    complexGenerated = generatedSpecs[0][:, 3:-3, :, 0] + 1.0j * generatedSpecs[0][:, 3:-3, :, 1]\n",
    "    complexOriginal = generatedSpecs[1][:, 3:-3, :, 0] + 1.0j * generatedSpecs[1][:, 3:-3, :, 1]\n",
    "\n",
    "    SNRs = _pavlovs_SNR(np.abs(complexOriginal), np.abs(complexGenerated), onAxis=(1, 2))\n",
    "    SNRs[np.isinf(SNRs)] = 0\n",
    "    return SNRs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4002, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_FMA_Context_Encoder/model-Papers_FMA_Context_Encoder2567124.ckpt\n",
      "Model restored.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amarafioti/.local/lib/python3.5/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log10\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_FMA_Context_Encoder/model-Papers_FMA_Context_Encoder2567124.ckpt\n",
      "Model restored.\n",
      "(3547, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_FMA_Context_Encoder/model-Papers_FMA_Context_Encoder2567124.ckpt\n",
      "Model restored.\n",
      "train mean SNR: 4.9019456\n",
      "train std SNR: 4.0436177\n",
      "valid mean SNR: 5.14429\n",
      "valid std SNR: 4.1795306\n",
      "test mean SNR: 5.4540076\n",
      "test std SNR: 4.4836307\n"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "train = scipy.io.loadmat('FMA_train_windows_16k.mat')\n",
    "print(train['fma_test'].shape)\n",
    "trainSNRs = computeInpaintingSNRFor(train['fma_test'])\n",
    "\n",
    "valid = scipy.io.loadmat('FMA_valid_windows_16k.mat')\n",
    "print(valid['fma_test'].shape)\n",
    "validSNRs = computeInpaintingSNRFor(valid['fma_test'])\n",
    "\n",
    "test = scipy.io.loadmat('FMA_test_windows_16k.mat')\n",
    "print(test['fma_test'].shape)\n",
    "testSNRs = computeInpaintingSNRFor(test['fma_test'])\n",
    "\n",
    "print('train mean SNR:', np.mean(trainSNRs))\n",
    "print('train std SNR:', np.std(trainSNRs))\n",
    "print('valid mean SNR:', np.mean(validSNRs))\n",
    "print('valid std SNR:', np.std(validSNRs))\n",
    "print('test mean SNR:', np.mean(testSNRs))\n",
    "print('test std SNR:', np.std(testSNRs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Encoder\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/input_data:0\", shape=(256, 16, 257, 4), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_0/Conv2D:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization/cond/Merge:0\", shape=(256, 8, 129, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_1/Conv2D:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_1:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_2/cond/Merge:0\", shape=(256, 4, 43, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_2/Conv2D:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_2:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_3/cond/Merge:0\", shape=(256, 2, 15, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_3/Conv2D:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_3:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_4/cond/Merge:0\", shape=(256, 2, 8, 256), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_4/Conv2D:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_4:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_5/cond/Merge:0\", shape=(256, 2, 8, 160), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Conv_5/Conv2D:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/Relu_5:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_6/cond/Merge:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "---------\n",
      "Fully\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/Encoder/batch_normalization_6/cond/Merge:0\", shape=(256, 2, 8, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Fully/MatMul:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Relu:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/batch_normalization/batchnorm/add_1:0\", shape=(256, 2048), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape_1:0\", shape=(256, 8, 8, 32), dtype=float32)\n",
      "---------\n",
      "Decoder\n",
      "---------\n",
      "Tensor(\"ContextEncoderArchitecture/Fully/Reshape_1:0\", shape=(256, 8, 8, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_0/conv2d_transpose:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization/cond/Merge:0\", shape=(256, 16, 16, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_1/conv2d_transpose:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_1:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_2/cond/Merge:0\", shape=(256, 32, 32, 512), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_2/conv2d_transpose:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_2:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_3/cond/Merge:0\", shape=(256, 32, 32, 257), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Reshape:0\", shape=(256, 8, 257, 128), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_3/conv2d_transpose:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Relu_3:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/batch_normalization_4/cond/Merge:0\", shape=(256, 16, 514, 11), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Reshape_1:0\", shape=(256, 11, 257, 32), dtype=float32)\n",
      "Tensor(\"ContextEncoderArchitecture/Decoder/Conv_4/conv2d_transpose:0\", shape=(256, 11, 257, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "sessionsName = \"Papers_Context_Encoder\"\n",
    "\n",
    "with open(architecturesParametersFile, 'rb') as savedFile:\n",
    "    Context_Encoder_parameters = pickle.load(savedFile)\n",
    "\n",
    "aContextEncoderArchitecture = ContextEncoderArchitecture(*Context_Encoder_parameters.architectureParameters())\n",
    "aPreProcessor = PreAndPostProcessor(*Context_Encoder_parameters.preProcessorParameters())\n",
    "aContextEncoderSystem = ContextEncoderSystem(aContextEncoderArchitecture, Context_Encoder_parameters.batchSize(),\n",
    "                                             aPreProcessor, sessionsName)\n",
    "\n",
    "best_step = 967467\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3894, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_Context_Encoder/model-Papers_Context_Encoder967467.ckpt\n",
      "Model restored.\n",
      "(3886, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_Context_Encoder/model-Papers_Context_Encoder967467.ckpt\n",
      "Model restored.\n",
      "(3984, 32000)\n",
      "INFO:tensorflow:Restoring parameters from utils/saved_models/Papers_Context_Encoder/model-Papers_Context_Encoder967467.ckpt\n",
      "Model restored.\n",
      "train mean SNR: 17.812756\n",
      "train std SNR: 10.517775\n",
      "valid mean SNR: 18.270575\n",
      "valid std SNR: 10.320516\n",
      "test mean SNR: 18.222937\n",
      "test std SNR: 10.133304\n"
     ]
    }
   ],
   "source": [
    "train = scipy.io.loadmat('NSynth_train_windows_16k.mat')\n",
    "print(train['nsynth_test'].shape)\n",
    "trainSNRs = computeInpaintingSNRFor(train['nsynth_test'])\n",
    "\n",
    "valid = scipy.io.loadmat('NSynth_valid_windows_16k.mat')\n",
    "print(valid['nsynth_test'].shape)\n",
    "validSNRs = computeInpaintingSNRFor(valid['nsynth_test'])\n",
    "\n",
    "test = scipy.io.loadmat('NSynth_test_windows_16k.mat')\n",
    "print(test['nsynth_test'].shape)\n",
    "testSNRs = computeInpaintingSNRFor(test['nsynth_test'])\n",
    "\n",
    "print('train mean SNR:', np.mean(trainSNRs))\n",
    "print('train std SNR:', np.std(trainSNRs))\n",
    "print('valid mean SNR:', np.mean(validSNRs))\n",
    "print('valid std SNR:', np.std(validSNRs))\n",
    "print('test mean SNR:', np.mean(testSNRs))\n",
    "print('test std SNR:', np.std(testSNRs))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
